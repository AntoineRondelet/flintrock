#!/usr/bin/env python -Wdefault
from __future__ import print_function

import boto.ec2 as ec2
import json
import PyYAML

import fabric.state
from fabric.api import task, local, parallel, run, env
from fabric.tasks import execute

env.colorize_errors = True
env.disable_known_hosts = True
# env.eagerly_disconnect = True
# env.keepalive = 30
# env.key_filename = "~/.ssh/nick.pem"
env.rcfile = ""
env.hosts = ['localhost', '127.0.0.1']

SUPPORTED_MODULES = {
    "spark": {
        "version": "1.3.0",
        "git-repo": "https://github.com/apache/spark"
    }
}


@parallel
def date():
    run("date")


def launch(provider, cluster_name, num_slaves, modules, provider_options):
    if provider == 'ec2':
        return launch_ec2(
            cluster_name=cluster_name,
            num_slaves=num_slaves,
            modules=modules,
            **provider_options)
    pass


# Move to ec2 module and call as ec2.launch()?
def launch_ec2(cluster_name, num_slaves, modules,
    key_name, identity_file,
    instance_type,
    region,
    availability_zone="",
    ami="",
    spot_price=None,
    vpc_id="", subnet_id="", placement_group="",
    tenancy="default", ebs_optimized=False,
    instance_initiated_shutdown_behavior="stop"):
    def get_or_create_security_group(region, name, vpc_id):
        connection = ec2.connect_to_region(region_name=region)
        group = connection.get_all_security_groups(groupnames=[name])[0]
        if not group:
            group = connection.create_security_group(
                name=name,
                description="flintrock-managed Spark group",
                vpc_id=vpc_id)
        return group
    security_group = get_or_create_security_group(region=region, name=cluster_name, vpc_id=vpc_id)
    image = connection.get_image(image_id=ami)
    reservation = image.run(
        min_count=(num_slaves + 1),
        max_count=(num_slaves + 1),
        key_name=key_name,
        instance_type=instance_type,
        placement=availability_zone,
        security_group_ids=[security_group.id],
        subnet_id=subnet_id,
        placement_group=placement_group,
        tenancy=tenancy,
        ebs_optimized=ebs_optimized,
        instance_initiated_shutdown_behavior=instance_initiated_shutdown_behavior)
    # TODO: Wait for all instances to come up. 
    #       This is OK for now because sooner or later we will wait for everything to be up.
    #       e.g. During final config of master/slaves.
    execute(task=provision_ec2_node, hosts=[i.public_dns_name for i in reservation.instances])
    # TODO: configure_master
    # TODO: allow for different setup of master and slaves
    pass


@parallel
# boto is not thread-safe so each task needs to create its own connection.
# Reference, from boto's primary maintainer: http://stackoverflow.com/a/19542645/
def provision_ec2_node(modules,
    identity_file):
    pass


def destroy(provider, cluster_name, assume_yes=False, provider_options):
    pass


def destroy_ec2(cluster_name, assume_yes=False,
    delete_groups=False):
    pass


def add_slaves(provider, cluster_name, num_slaves, provider_options):
    pass


def add_slaves_ec2(cluster_name, num_slaves,
    identity_file):
    pass


def remove_slaves(provider, cluster_name, num_slaves, assume_yes=False, provider_options):
    pass


def remove_slaves_ec2(cluster_name, num_slaves, assume_yes=False):
    pass


def describe(provider, cluster_name, master_hostname_only=False, provider_options):
    pass


def describe_ec2(cluster_name, master_hostname_only=False):
    pass


def login(provider, cluster_name, provider_options):
    pass


def login_ec2(cluster_name):
    pass


def start(provider, cluster_name, provider_options):
    pass


def start_ec2(cluster_name):
    pass


def stop(provider, cluster_name, assume_yes=False, provider_options):
    pass


def stop_ec2(cluster_name, assume_yes=False):
    pass


# print(json.dumps(env, indent=True))
# print(json.dumps(fabric.state.commands, indent=True))
